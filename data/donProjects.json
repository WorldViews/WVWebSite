{
   "projects": [
      {
         "description": "<p><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image020.gif\" width=\"185\" height=\"377\" /></p>\n<p>Since 2015&nbsp;<span class=\"GramE\">I&rsquo;ve</span>&nbsp;been involved with the Arts &amp; Technology nonprofit&nbsp;<a href=\"http://kinetecharts.org/\">Kinetech Arts</a>, first through participation in&nbsp;<a href=\"http://www.dancehack.org/\"><span class=\"SpellE\">DanceHack</span></a>, and serving on their board of directors since 2017.&nbsp; <span class=\"SpellE\">DanceHack</span>&nbsp;<span class=\"GramE\">teams</span>&nbsp;digital artists, technologists, musicians and dancers on performance projects.&nbsp;&nbsp;My first project was with whirling dancer&nbsp;<a href=\"https://raquelsantiago.es/\">Raquel Santiago</a>.&nbsp;&nbsp;I created a 3D animation, expressing Raquel&rsquo;s spiritual interpretation of her dancing together with a fabric simulation of her skirt, using three.js.&nbsp;&nbsp;A&nbsp;<span class=\"SpellE\">blueto</span><span class=\"SpellE\">oth</span>&nbsp;IMU sensor synchronized the animation with Raquel&rsquo;s orientation as she danced.&nbsp;&nbsp;Another year, I captured 360&nbsp;<span class=\"GramE\">video</span>&nbsp;of dancers performing around a central cone.&nbsp;&nbsp;Live or recorded video projected onto the cone provided a panoramic display.&nbsp;&nbsp;This led to the patent of a Panoramic Portal device that could connect people at different locations through 360&nbsp;<span class=\"GramE\">video</span>.&nbsp;&nbsp;A 2018 design study for a possible&nbsp;<span class=\"SpellE\">DanceHack</span>&nbsp;project led to Reactive Video, in which a movement artist could perform with a video player that stayed synchronized with their movement.&nbsp;&nbsp;I co-chaired the 2017 ACM Multimedia Interactive Art&nbsp;<span class=\"GramE\">exhibition, and</span>&nbsp;hosted an&nbsp;<a href=\"https://sites.google.com/site/bammf2/past-bammf-1/10thbammf\">Arts &amp; Tech event</a> for the Bay Area Multimedia Forum.</p>",
         "id": "proj_1616600137_934",
         "name": "Kinetech Arts & DanceHack"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class =\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image018.gif\" width=\"253\" height=\"253\" />MASAL stands for Modulated Ambient Sound And&nbsp;Light, and&nbsp;is the theme of how light and sound sources can be used not only for human needs like illumination or background music, but can carry signals used by devices for tasks like positioning and navigation.&nbsp;&nbsp;One project in this space used music playing from different speakers and a phone app could determine which zone it was in by which music was detected. It could also work using&nbsp;very soft&nbsp;barely audible background white noise.&nbsp;&nbsp;(Some products intentionally produce this in public spaces to &lsquo;soften&rsquo; the acoustics.)&nbsp;&nbsp;&nbsp;In rooms with multiple speakers, the acoustics could be used to determine the phone&rsquo;s position to sub meter accuracy, using time difference of arrival and&nbsp;trilateralization.&nbsp;&nbsp;I also developed a positioning app that could use ambient acoustic fingerprinting, detected sounds in known zones,&nbsp;Wifi&nbsp;signal strength, optional image features, and IMU readings, fused using a Hidden Markov Model for fusion.</p>\n<p style=\"font-weight: 400;\">&nbsp;</p>\n<p style=\"font-weight: 400;\">IPIN 2012, &ldquo;Indoor localization using controlled ambient sounds&rdquo;, I. Rishab, D. Kimber, J. Adcock. <a href=\"https://www.fxpal.com/publications/indoor-localization-using-controlled-ambient-sounds.pdf\">pdf</a></p>\n<p style=\"font-weight: 400;\">IPIN 2012, &ldquo;Mirror Worlds for indoor navigation and awareness&rdquo;, D. Kimber, D. Lee, J. Vaughan, J. Biel, M. Cooper, J.Shingu.&nbsp;<a href=\"https://www.fxpal.com/publications/mirror-worlds-for-indoor-navigation-and-awareness.pdf\">pdf</a></p>\n<p style=\"font-weight: 400;\">,&nbsp;</p>\n<p style=\"font-weight: 400;\">&nbsp;</p>",
         "id": "proj_1616600476_927",
         "name": "MASAL & Explorer"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image002.gif\" width=\"213\" height=\"252\" />In collaboration with&nbsp;<a href=\"https://www.usfca.edu/\">USFCA</a>,&nbsp;<a href=\"https://www.kineviz.com/\">Kineviz</a>&nbsp;and&nbsp;<a href=\"http://kinetecharts.org/\">Kinetech Arts</a>, I&rsquo;m currently working on a system for agent based social modeling and simulation.&nbsp;&nbsp;We are building a JavaScript simulation engine with interfaces through&nbsp;<a href=\"https://observablehq.com/\">ObservableHQ</a>&nbsp;and the Kineviz GraphXR visualization platform.&nbsp;&nbsp;A number of different models are under development, including for cognitive and emotional contagion (e.g.&nbsp;effect on happiness from random acts of kindness) and for spread of ideologies and polarization in social networks.&nbsp;&nbsp;We plan to explore models for both synthetic and real data sets.&nbsp;&nbsp;A&nbsp;short term&nbsp;goal is to describe and compare some different mechanisms that can account for ideological polarization - &ldquo;the divide&rdquo; of our current society, and how different social media affect this.&nbsp;&nbsp;The models will be available and used for interactive simulations, as well as by artists in the Kinetech Arts community for artistic performance or installation.</p>\n<p style=\"font-weight: 400;\"><a href=\"https://observablehq.com/@donkimber/random-acts-of-kindness\">Kindness Contagion Notebook</a></p>\n<p style=\"font-weight: 400;\">&nbsp;</p>\n<p style=\"font-weight: 400;\">&nbsp;</p>",
         "id": "proj_1616600625_721",
         "name": "Social Modeling and Simulations"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image004.gif\" width=\"167\" height=\"309\" />Standard video players have no user model, and simply play, pause, scrub, etc. in reaction to UI controls.&nbsp;&nbsp;Reactive video, like a good instructor, tracks the user, and plays the video in a manner appropriate to the user&rsquo;s activity.&nbsp;&nbsp;For a physical training activity, say Tai Chi, the player synchronizes the video to match the user&rsquo;s movement.&nbsp;&nbsp;One practical value of this is that the user&nbsp;doesn&rsquo;t&nbsp;fuss so much with a UI to get the video to pause or repeat.&nbsp;&nbsp;An experiential value is that it changes video from a passive experience of watching and following, to one of being connected with the video, for a more immersive and engaging experience.&nbsp;&nbsp;The system uses a Kinect or&nbsp;OpenPose&nbsp;to track body movement for the reference training video and Kinect or&nbsp;Posenet&nbsp;for the live user. There are several use modes.&nbsp;&nbsp;In one, a user simply watches the video of a movement, and attempts to passively follow the movement.&nbsp;&nbsp;Subsets of tracked joints can be chosen and used to find a best alignment of user and reference movements (with adjustment made for different body sizes.)&nbsp;&nbsp;Visual indicators are drawn on the video to give feedback about alignment and to show the paths joints should follow, and changes made to a musical or soundscape background for feedback and motivation.&nbsp;&nbsp;Afterwards, graphs of the alignment as a function of time through a movement can be examined by the user or an instructor.</p>\n<p style=\"font-weight: 400;\">&nbsp;</p>\n<p style=\"font-weight: 400;\">UIST 2020, &ldquo;Reactive Video: Adaptive Video Playback Based on User Motion for Supporting Physical Activity&rdquo;, C. Clarke, D.&nbsp;Cavdir, P. Chiu, L.&nbsp;Denoue, D. Kimber.&nbsp;&nbsp;<a href=\"https://dl.acm.org/doi/abs/10.1145/3379337.3415591\">paper</a>&nbsp;video:&nbsp;<a href=\"https://www.youtube.com/watch?v=pvlQZf7Rj2s&amp;t=123s\">15min</a>&nbsp;<a href=\"https://www.youtube.com/watch?v=RqKe6NAZpko&amp;t=88s\">5min</a></p>\n<p style=\"font-weight: 400;\"><u>&nbsp;</u></p>\n<p style=\"font-weight: 400;\">&nbsp;</p>",
         "id": "proj_1616600733_392",
         "name": "Reactive Video"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image006.gif\" width=\"186\" height=\"281\" />In collaboration with Derrick Kikuchi at Reach and Teach, and occupational therapist Sydney&nbsp;Shiroyama, who uses taiko drumming therapeutically for special needs clients and communities, I&rsquo;m developing software and&nbsp;hardware based&nbsp;rhythm games.&nbsp;&nbsp;The core of the system is a MIDI based rhythm engine that can synchronize with users in playing rhythms.&nbsp;&nbsp;As with reactive video, there is a passive mode in which users follow a rhythm pattern and get feedback on how well they are doing.&nbsp;&nbsp;In another mode the system seeks to follow the flow of the user.&nbsp;&nbsp;The engine runs in a web page, shows the rhythm patterns radially as on a clock, and can play preset songs, or songs can be entered using drum languages of various drum communities, such as&nbsp;kuchi&nbsp;shoga&nbsp;for Taiko.&nbsp;&nbsp;The web page can&nbsp;be connected with&nbsp;midi devices, such as keyboards, drum pads, or devices designed for air drumming, such as&nbsp;<a href=\"https://www.senstroke.com/\">senstroke</a>. It can also connect to and control external&nbsp;arduino&nbsp;devices, such as a &ldquo;RhythmStick&rdquo;, that has lights showing beats, and using an accelerometer to detect drum strokes.&nbsp;&nbsp;The system is on display at Reach and Teach, where Derrick is observing how users interact with it using drums in the store, such as the &ldquo;sun moon star&rdquo; drum pictured above.&nbsp;</p>\n<p style=\"font-weight: 400;\">&nbsp;</p>",
         "id": "proj_1616600844_027",
         "name": "RhythmSticks"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image008.gif\" width=\"297\" height=\"179\" />MUSE is a high level vision with several key themes.&nbsp;&nbsp;One is to &lsquo;move the web browser out of the display and into the room&rsquo;.&nbsp;&nbsp;A MUSE venue is a virtual or real room (e.g. black box theatre) that is a sort of &lsquo;program browser&rsquo; that can display exhibits, programs, games, support sharing of media content, for programs, games, simulations, etc.&nbsp;&nbsp;The MUSE activity.&nbsp;&nbsp;Show Pano Portal and Reach and Teach collaboration.&nbsp;&nbsp;Magic Theater.</p>\n<p style=\"font-weight: 400;\">Reusable media content.</p>\n<p style=\"font-weight: 400;\">&nbsp;</p>",
         "id": "proj_1616601036_113",
         "name": "MUSE & Magic Spaces"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image016.gif\" width=\"227\" height=\"282\" />During years of working on 360&nbsp;video, I had always wanted to do a project where someone stuck in a hospital could connect to and control a robot with a 360 camera or a steerable camera.&nbsp;&nbsp;When I started working on such a project it occurred to me that&nbsp;I&rsquo;d&nbsp;rather connect them with a human guide.&nbsp;&nbsp;The remote person could be like a parrot riding the guide&rsquo;s shoulder.&nbsp;&nbsp;The Polly project implemented various incarnations of this idea, with the most advanced using a phone on a gimbal that could provide stabilization and view control.&nbsp;&nbsp;Guides carrying Polly devices and viewers could meet in a google hangout, and the remote participants could use an interface in the hangout to control the camera.&nbsp;&nbsp;A high point of this project was the chance to work with&nbsp;<a href=\"https://www.ted.com/talks/henry_evans_and_chad_jenkins_meet_the_robots_for_humanity?language=en\">Henry Evans</a>&nbsp;and provide him with virtual tours.</p>\n<p style=\"font-weight: 400;\">ACVR 2014, &ldquo;Polly: Telepresence from a Guide&rsquo;s Shoulder&rdquo;, D. Kimber, P.&nbsp;Proppe, S. Kratz, J. Vaughan, B. Liew, D.&nbsp;Severns, W.&nbsp;Su.&nbsp;&nbsp;<a href=\"http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/ECCV_2014/workshops/w22/W22-44.pdf\">pdf</a>&nbsp;&nbsp;<a href=\"https://www.youtube.com/watch?v=jnpGKvSGt4E\">Henry Evans video</a>.</p>",
         "id": "proj_1616610069_88",
         "name": "Polly & Remote Telepresence"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image014.gif\" width=\"235\" height=\"189\" />I&rsquo;ve&nbsp;worked for m<img src=\"float:right;\" alt=\"\" />any years on 360 video tours, where panoramic video is collected along paths and reindexed by position.&nbsp;&nbsp;This allows users to take virtual tours by moving along paths and looking in any direction.&nbsp;&nbsp;It&rsquo;s similar to street view, or many types of 360 tours (e.g.&nbsp;QTVR) except the user can move forward or backward along a path, and see video of the movement, rather than transitions from one fixed point to another.&nbsp;&nbsp;Some versions of our viewer supported an HMD, and joystick control, and when users reached path intersections, they could seamlessly choose a path with the joystick.&nbsp;&nbsp;Mostly though,&nbsp;I&rsquo;ve&nbsp;focused on web delivered virtual tours, viewable on screen, phone or tablet.&nbsp;&nbsp;The imaging technology has matured, and now high-quality video is easily captured with consumer cameras.&nbsp;&nbsp;The spatial imagining has also improved.&nbsp;&nbsp;Initially we used a combination of hand registration for indoor, and GPS for outdoor.&nbsp;&nbsp;Now GPS is ubiquitous, and phones can perform SLAM.&nbsp;&nbsp;Recently we used OpenVSLAM, which produces highly accurate spatial indices.&nbsp;&nbsp;Follow on projects in this area have been part of WorldViews and presented with its viewers.</p>\n<p style=\"font-weight: 400;\">ACM MM 2001 &ldquo;FlyAbout:Spatially&nbsp;Indexed Panoramic Video&rdquo; D. Kimber, J. Foote, S. Lertsithichai.&nbsp;<a href=\"https://www.fxpal.com/publications/flyaboutspatially-indexed-panoramic-video.pdf\">pdf</a>&nbsp;<a href=\"https://www.youtube.com/watch?v=NIziO0u7zsU\">video</a></p>",
         "id": "proj_1616610205_28",
         "name": "360 Video Virtual Tours"
      },
      {
         "description": "<p style=\"font-weight: 400;\"><img class=\"projpic\" src=\"https://worldviews.org/donkimber/DonKimberProjects_files/image010.gif\" width=\"329\" height=\"215\" />A mirror world is a virtual model of a real physical space, which may be updated with various sensors or data feeds to indicate things about the state of the world.&nbsp;&nbsp;It is like a living 3D map and has many uses.&nbsp;&nbsp;A mirror world of a conference venue may be used to market the venue, to plan for a conference, by presenters or conference attendees to plan presentations or itineraries.&nbsp;&nbsp;During the conference, it can be used as a portal for remote people to virtually attend the conference or can be used afterwards to show a recording of the conference.&nbsp;&nbsp;I&rsquo;ve been involved in creating Mirror Worlds for several venues and locations, and platforms with several different 3D viewers - Google Earth, Unity3D, OpenSceneGraph and VRML.</p>\n<p style=\"font-weight: 400;\">ACM MM2012&nbsp;&nbsp;&ldquo;Through the Looking-Glass: Mirror Worlds for Augmented Awareness &amp; Capability&rdquo;, D. Kimber, J.&nbsp;Shingu, J. Vaughan.&nbsp;&nbsp;&nbsp;<a href=\"https://www.fxpal.com/wp-content/uploads/2015/10/PR-12-806.pdf\">pdf</a>&nbsp;<a href=\"https://www.youtube.com/watch?v=f_cT66P8C2I&amp;t=135s\">video</a></p>\n<p style=\"font-weight: 400;\">ACM MM2007, &ldquo;DOTS: Support for Effective Video Surveillance&rdquo;, A.&nbsp;Girgensohn, D. Kimber, J. Vaughan, T. Yang, F. Shipman, T. Turner, E.&nbsp;Rieffel, L. Wilcox, F.&nbsp;Chen&nbsp;and T. Dunnigan.&nbsp;<a href=\"https://www.fxpal.com/publications/dots-support-for-effective-video-surveillance-2.pdf\">pdf</a>&nbsp;<a href=\"https://xfxpal.com/videos\">video</a></p>",
         "id": "proj_1616610345_964",
         "name": "Mirror Worlds"
      }
   ],
   "urls": {
      "obj_1595791445_808": {
         "id": "obj_1595791445_808",
         "type": "URL",
         "url": "http://worldviews.org"
      },
      "obj_1595792869_467": {
         "id": "obj_1595792869_467",
         "type": "URL",
         "url": "https://www.roys-station.com/"
      },
      "obj_1595792894_331": {
         "id": "obj_1595792894_331",
         "type": "URL",
         "url": "http://www.gardenofparadise.net/Home.html"
      }
   }
}